{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Image Classification with Google MobileNetV2"]},{"cell_type":"markdown","metadata":{},"source":["## Import Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:11.387234Z","iopub.status.busy":"2024-05-26T19:02:11.386433Z","iopub.status.idle":"2024-05-26T19:02:15.945952Z","shell.execute_reply":"2024-05-26T19:02:15.945132Z","shell.execute_reply.started":"2024-05-26T19:02:11.387198Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","import os\n","from IPython.display import Image\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from matplotlib.pyplot import imread\n","from sklearn.metrics import classification_report, accuracy_score\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator # type: ignore\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","import kagglehub\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:15.948439Z","iopub.status.busy":"2024-05-26T19:02:15.947541Z","iopub.status.idle":"2024-05-26T19:02:15.954868Z","shell.execute_reply":"2024-05-26T19:02:15.953624Z","shell.execute_reply.started":"2024-05-26T19:02:15.948409Z"},"trusted":true},"outputs":[],"source":["# Kinds of flowers\n","kinds = np.array(os.listdir('C:/fruit_recognition/client/src/predict/archive/train'))\n","print(f\"Kinds in this dataset: {kinds}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:15.956728Z","iopub.status.busy":"2024-05-26T19:02:15.956267Z","iopub.status.idle":"2024-05-26T19:02:15.974147Z","shell.execute_reply":"2024-05-26T19:02:15.973344Z","shell.execute_reply.started":"2024-05-26T19:02:15.956689Z"},"trusted":true},"outputs":[],"source":["# Paths of directories\n","path = 'C:/fruit_recognition/client/src/predict/archive/train'\n","kind_path = [path + \"/\" + year for year in kinds]\n","kind_path"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:15.977037Z","iopub.status.busy":"2024-05-26T19:02:15.976674Z","iopub.status.idle":"2024-05-26T19:02:16.000950Z","shell.execute_reply":"2024-05-26T19:02:16.000085Z","shell.execute_reply.started":"2024-05-26T19:02:15.977007Z"},"trusted":true},"outputs":[],"source":["# Numbers of flowers for each kinds\n","for i, kind in enumerate(kind_path):\n","    print(f\"There are {len(os.listdir(kind))} pictures in {kinds[i]}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:16.002117Z","iopub.status.busy":"2024-05-26T19:02:16.001854Z","iopub.status.idle":"2024-05-26T19:02:26.572360Z","shell.execute_reply":"2024-05-26T19:02:26.571396Z","shell.execute_reply.started":"2024-05-26T19:02:16.002082Z"},"trusted":true},"outputs":[],"source":["# Example images for each kinds\n","plt.figure(figsize=(10, 4))\n","plt.suptitle(\"Example Images\")\n","\n","num_kinds = len(kinds)\n","num_cols = min(num_kinds, 9)  # Ensure maximum of 9 columns\n","num_rows = (num_kinds + num_cols - 1) // num_cols\n","\n","for i, kind in enumerate(kinds):\n","    ax = plt.subplot(num_rows, num_cols, i + 1)\n","    # Get all JPG files in the directory\n","    jpg_files = [file for file in os.listdir(kind_path[i]) if file.lower().endswith('.jpg')]\n","    # Use the first file if available\n","    if jpg_files:\n","        path = os.path.join(kind_path[i], jpg_files[0])\n","        img = plt.imread(path)\n","        plt.imshow(img)\n","        plt.title(kind.capitalize())\n","        plt.axis(\"off\")\n","    else:\n","        print(f\"No JPG file found in directory: {kind_path[i]}\")\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:26.573914Z","iopub.status.busy":"2024-05-26T19:02:26.573608Z","iopub.status.idle":"2024-05-26T19:02:26.603016Z","shell.execute_reply":"2024-05-26T19:02:26.602164Z","shell.execute_reply.started":"2024-05-26T19:02:26.573887Z"},"trusted":true},"outputs":[],"source":["# All ids\n","\n","\n","id_df = []\n","for i in range(len(kinds)):\n","    # 获取 kind_path[i] 目录下所有以 .jpg 结尾的文件\n","    jpg_files = [img.split(\".\")[0] for img in os.listdir(kind_path[i]) if img.lower().endswith('.jpg')]\n","    id_df.extend(jpg_files)\n","\n","len(id_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:26.604403Z","iopub.status.busy":"2024-05-26T19:02:26.604077Z","iopub.status.idle":"2024-05-26T19:02:26.631451Z","shell.execute_reply":"2024-05-26T19:02:26.630506Z","shell.execute_reply.started":"2024-05-26T19:02:26.604370Z"},"trusted":true},"outputs":[],"source":["# All kinds\n","kind_df = []\n","for i, kind in enumerate(kinds):\n","    # 获取 kind_path[i] 目录下所有以 .jpg 结尾的文件\n","    jpg_files = os.listdir(kind_path[i])\n","    jpg_files = [img.split(\".\")[0] for img in jpg_files if img.lower().endswith('.jpg')]\n","    for x in range(len(jpg_files)):\n","        kind_df.append(kind)\n","\n","len(kind_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:26.632823Z","iopub.status.busy":"2024-05-26T19:02:26.632543Z","iopub.status.idle":"2024-05-26T19:02:26.650167Z","shell.execute_reply":"2024-05-26T19:02:26.649188Z","shell.execute_reply.started":"2024-05-26T19:02:26.632791Z"},"trusted":true},"outputs":[],"source":["# Create a dataframe\n","df = pd.DataFrame(columns=[\"id\", \"kind\"])\n","df[\"id\"] = id_df\n","df[\"kind\"] = kind_df\n","df.tail()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:26.651999Z","iopub.status.busy":"2024-05-26T19:02:26.651701Z","iopub.status.idle":"2024-05-26T19:02:26.661152Z","shell.execute_reply":"2024-05-26T19:02:26.660170Z","shell.execute_reply.started":"2024-05-26T19:02:26.651976Z"},"trusted":true},"outputs":[],"source":["# Check numbers\n","df[\"kind\"].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:26.665530Z","iopub.status.busy":"2024-05-26T19:02:26.665219Z","iopub.status.idle":"2024-05-26T19:02:26.690777Z","shell.execute_reply":"2024-05-26T19:02:26.689695Z","shell.execute_reply.started":"2024-05-26T19:02:26.665504Z"},"trusted":true},"outputs":[],"source":["filenames = []\n","for i in range(len(kinds)):\n","    # 获取 kind_path[i] 目录下所有以 .jpg 结尾的文件\n","    jpg_files = [kind_path[i] + \"/\" + kind for kind in os.listdir(kind_path[i]) if kind.lower().endswith('.jpg')]\n","    filenames.extend(jpg_files)\n","\n","filenames[:5]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:26.692297Z","iopub.status.busy":"2024-05-26T19:02:26.691988Z","iopub.status.idle":"2024-05-26T19:02:26.698360Z","shell.execute_reply":"2024-05-26T19:02:26.697163Z","shell.execute_reply.started":"2024-05-26T19:02:26.692272Z"},"trusted":true},"outputs":[],"source":["# Check a random flower\n","print(filenames[2317])\n","print(df.loc[2317])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:26.699777Z","iopub.status.busy":"2024-05-26T19:02:26.699498Z","iopub.status.idle":"2024-05-26T19:02:26.719720Z","shell.execute_reply":"2024-05-26T19:02:26.718696Z","shell.execute_reply.started":"2024-05-26T19:02:26.699753Z"},"trusted":true},"outputs":[],"source":["boolean_kinds = [kind == kinds for kind in kind_df ]\n","boolean_kinds[:5]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:26.721367Z","iopub.status.busy":"2024-05-26T19:02:26.720973Z","iopub.status.idle":"2024-05-26T19:02:26.729904Z","shell.execute_reply":"2024-05-26T19:02:26.728955Z","shell.execute_reply.started":"2024-05-26T19:02:26.721338Z"},"trusted":true},"outputs":[],"source":["len(boolean_kinds)"]},{"cell_type":"markdown","metadata":{},"source":["## Creating test and train sets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:26.731641Z","iopub.status.busy":"2024-05-26T19:02:26.731249Z","iopub.status.idle":"2024-05-26T19:02:26.738121Z","shell.execute_reply":"2024-05-26T19:02:26.737158Z","shell.execute_reply.started":"2024-05-26T19:02:26.731606Z"},"trusted":true},"outputs":[],"source":["X = filenames\n","y = boolean_kinds"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:26.739694Z","iopub.status.busy":"2024-05-26T19:02:26.739373Z","iopub.status.idle":"2024-05-26T19:02:26.752732Z","shell.execute_reply":"2024-05-26T19:02:26.751704Z","shell.execute_reply.started":"2024-05-26T19:02:26.739656Z"},"trusted":true},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X,\n","                                                    y,\n","                                                    test_size=0.2,\n","                                                    random_state=18)\n","len(X_train), len(X_test), len(y_train), len(y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:26.754260Z","iopub.status.busy":"2024-05-26T19:02:26.753871Z","iopub.status.idle":"2024-05-26T19:02:26.767196Z","shell.execute_reply":"2024-05-26T19:02:26.766258Z","shell.execute_reply.started":"2024-05-26T19:02:26.754210Z"},"trusted":true},"outputs":[],"source":["X_train[:3], y_train[:3]"]},{"cell_type":"markdown","metadata":{},"source":["## Preprocessing Images"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:26.768869Z","iopub.status.busy":"2024-05-26T19:02:26.768500Z","iopub.status.idle":"2024-05-26T19:02:26.798196Z","shell.execute_reply":"2024-05-26T19:02:26.797266Z","shell.execute_reply.started":"2024-05-26T19:02:26.768835Z"},"trusted":true},"outputs":[],"source":["image = imread(filenames[15])\n","image.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:26.799579Z","iopub.status.busy":"2024-05-26T19:02:26.799284Z","iopub.status.idle":"2024-05-26T19:02:26.808020Z","shell.execute_reply":"2024-05-26T19:02:26.807046Z","shell.execute_reply.started":"2024-05-26T19:02:26.799555Z"},"trusted":true},"outputs":[],"source":["image.max(), image.min()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:26.809819Z","iopub.status.busy":"2024-05-26T19:02:26.809487Z","iopub.status.idle":"2024-05-26T19:02:26.818331Z","shell.execute_reply":"2024-05-26T19:02:26.817408Z","shell.execute_reply.started":"2024-05-26T19:02:26.809793Z"},"trusted":true},"outputs":[],"source":["image[:50]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:26.819954Z","iopub.status.busy":"2024-05-26T19:02:26.819609Z","iopub.status.idle":"2024-05-26T19:02:27.264127Z","shell.execute_reply":"2024-05-26T19:02:27.263032Z","shell.execute_reply.started":"2024-05-26T19:02:26.819927Z"},"trusted":true},"outputs":[],"source":["# turn image into a tensor\n","tf.constant(image)[:2]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:27.266079Z","iopub.status.busy":"2024-05-26T19:02:27.265620Z","iopub.status.idle":"2024-05-26T19:02:27.271308Z","shell.execute_reply":"2024-05-26T19:02:27.270176Z","shell.execute_reply.started":"2024-05-26T19:02:27.266043Z"},"trusted":true},"outputs":[],"source":["img_size = 224"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:27.272931Z","iopub.status.busy":"2024-05-26T19:02:27.272599Z","iopub.status.idle":"2024-05-26T19:02:27.281795Z","shell.execute_reply":"2024-05-26T19:02:27.280733Z","shell.execute_reply.started":"2024-05-26T19:02:27.272893Z"},"trusted":true},"outputs":[],"source":["# Create a function for preprocessing images\n","def process_image(image_path, img_size=img_size):\n","  # Read in an image file\n","  image = tf.io.read_file(image_path)\n","  # Turn the jpeg image into numerical Tensor with 3 colour channels (Red, Green, Blue)\n","  image = tf.image.decode_jpeg(image, channels=3)\n","  # Convert the colour channel values from 0-255 to 0-1 values\n","  image = tf.image.convert_image_dtype(image, tf.float32)\n","  # Resize the image to our desired value (224, 224)\n","  image = tf.image.resize(image, size=[img_size, img_size])\n","\n","  return image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:27.283370Z","iopub.status.busy":"2024-05-26T19:02:27.282999Z","iopub.status.idle":"2024-05-26T19:02:27.328189Z","shell.execute_reply":"2024-05-26T19:02:27.327157Z","shell.execute_reply.started":"2024-05-26T19:02:27.283342Z"},"trusted":true},"outputs":[],"source":["process_image(X[17]), tf.constant(y[17])"]},{"cell_type":"markdown","metadata":{},"source":["## Creating data batches"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:27.329950Z","iopub.status.busy":"2024-05-26T19:02:27.329558Z","iopub.status.idle":"2024-05-26T19:02:27.335001Z","shell.execute_reply":"2024-05-26T19:02:27.333955Z","shell.execute_reply.started":"2024-05-26T19:02:27.329913Z"},"trusted":true},"outputs":[],"source":["# Create a simple function to return a tuple (image, label)\n","def get_image_label (image_path, label):\n","  image = process_image(image_path)\n","  return image, label"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:27.336954Z","iopub.status.busy":"2024-05-26T19:02:27.336371Z","iopub.status.idle":"2024-05-26T19:02:27.345379Z","shell.execute_reply":"2024-05-26T19:02:27.344382Z","shell.execute_reply.started":"2024-05-26T19:02:27.336918Z"},"trusted":true},"outputs":[],"source":["batch_size = 32"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:27.346922Z","iopub.status.busy":"2024-05-26T19:02:27.346556Z","iopub.status.idle":"2024-05-26T19:02:27.355829Z","shell.execute_reply":"2024-05-26T19:02:27.354922Z","shell.execute_reply.started":"2024-05-26T19:02:27.346896Z"},"trusted":true},"outputs":[],"source":["# Create a function to turn data into batches\n","def create_data_batches(X, y=None, batch_size=batch_size, test_data=False):\n","        data = tf.data.Dataset.from_tensor_slices((tf.constant(X),\n","                                                   tf.constant(y)))\n","        # Shuffling pathnames and labels before mapping image processor function is faster than shuffling images\n","        data = data.shuffle(buffer_size=len(X))\n","\n","        # Create (image, label) tuples (this also turns the iamge path into a preprocessed image)\n","        data = data.map(get_image_label)\n","\n","        # Turn the training data into batches\n","        data_batch = data.batch(batch_size)\n","        return data_batch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:27.357398Z","iopub.status.busy":"2024-05-26T19:02:27.357031Z","iopub.status.idle":"2024-05-26T19:02:27.516963Z","shell.execute_reply":"2024-05-26T19:02:27.516159Z","shell.execute_reply.started":"2024-05-26T19:02:27.357371Z"},"trusted":true},"outputs":[],"source":["# Create training and validation data batches\n","train_data = create_data_batches(X_train, y_train)\n","test_data = create_data_batches(X_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:27.524318Z","iopub.status.busy":"2024-05-26T19:02:27.523969Z","iopub.status.idle":"2024-05-26T19:02:27.532855Z","shell.execute_reply":"2024-05-26T19:02:27.531920Z","shell.execute_reply.started":"2024-05-26T19:02:27.524289Z"},"trusted":true},"outputs":[],"source":["train_data.element_spec, test_data.element_spec"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:27.535440Z","iopub.status.busy":"2024-05-26T19:02:27.534947Z","iopub.status.idle":"2024-05-26T19:02:28.738090Z","shell.execute_reply":"2024-05-26T19:02:28.736988Z","shell.execute_reply.started":"2024-05-26T19:02:27.535403Z"},"trusted":true},"outputs":[],"source":["train_images, train_labels = next(train_data.as_numpy_iterator())\n","#test_images, test_labels = next(test_data.as_numpy_iterator())\n","train_images[:2], train_labels[:2]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:28.739893Z","iopub.status.busy":"2024-05-26T19:02:28.739490Z"},"trusted":true},"outputs":[],"source":["# Visualizing data batches\n","plt.figure(figsize=(10, 10))\n","for i in range(25):\n","    ax = plt.subplot(5, 5, i+1)\n","    plt.imshow(train_images[i])\n","    plt.title(kinds[train_labels[i].argmax()])\n","    plt.axis(\"off\")"]},{"cell_type":"markdown","metadata":{},"source":["## Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:30.720321Z","iopub.status.busy":"2024-05-26T19:02:30.719998Z","iopub.status.idle":"2024-05-26T19:02:30.725874Z","shell.execute_reply":"2024-05-26T19:02:30.724899Z","shell.execute_reply.started":"2024-05-26T19:02:30.720295Z"},"trusted":true},"outputs":[],"source":["# Setup input shape to the model\n","input_shape = (None, img_size, img_size, 3) # batch, height, width, colour channels\n","# Setup output shape of our model\n","output_shape = len(kinds)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import kagglehub\n","\n","# Download latest version\n","path = kagglehub.model_download(\"google/mobilenet-v2/tensorFlow2/140-224-classification\")\n","\n","print(\"Path to model files:\", path)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:30.727920Z","iopub.status.busy":"2024-05-26T19:02:30.727259Z","iopub.status.idle":"2024-05-26T19:02:32.865728Z","shell.execute_reply":"2024-05-26T19:02:32.864618Z","shell.execute_reply.started":"2024-05-26T19:02:30.727874Z"},"trusted":true},"outputs":[],"source":["model = tf.keras.Sequential([\n","    tf.keras.layers.Lambda(lambda x: hub.KerasLayer(\"C:/Users/thang/.cache/kagglehub/models/google/mobilenet-v2/tensorFlow2/140-224-classification/2\")(x)),  # MobileNet V2作为特征提取器\n","    tf.keras.layers.BatchNormalization(),  # 批归一化层\n","    tf.keras.layers.Dense(units=output_shape, activation=\"softmax\")  # 输出层\n","    \n","])"]},{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"sequential_7\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ lambda_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1001</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1001</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,004</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,020</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ lambda_6 (\u001b[38;5;33mLambda\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1001\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1001\u001b[0m)           │         \u001b[38;5;34m4,004\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m10,020\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,024</span> (54.78 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,024\u001b[0m (54.78 KB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,022</span> (46.96 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,022\u001b[0m (46.96 KB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,002</span> (7.82 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,002\u001b[0m (7.82 KB)\n"]},"metadata":{},"output_type":"display_data"}],"source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","\n","# Define the output shape (number of classes)\n","output_shape = 10  # Change this to match the number of your output classes\n","\n","# Define a function to wrap the TensorFlow Hub layer\n","def mobilenet_v2_layer():\n","    return hub.KerasLayer(\"C:/Users/thang/.cache/kagglehub/models/google/mobilenet-v2/tensorFlow2/140-224-classification/2\", \n","                          trainable=False)\n","\n","# Create the Sequential model\n","model = tf.keras.Sequential([\n","    tf.keras.layers.InputLayer(input_shape=(224, 224, 3)),  # Input shape for MobileNet V2\n","    tf.keras.layers.Lambda(lambda x: mobilenet_v2_layer()(x)),  # Wrap the Hub layer\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.Dense(units=output_shape, activation=\"softmax\")\n","])\n","\n","# Print the model summary\n","model.summary()\n"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:32.867923Z","iopub.status.busy":"2024-05-26T19:02:32.867540Z","iopub.status.idle":"2024-05-26T19:02:32.892586Z","shell.execute_reply":"2024-05-26T19:02:32.891634Z","shell.execute_reply.started":"2024-05-26T19:02:32.867890Z"},"trusted":true},"outputs":[],"source":["  model.compile(\n","      loss=tf.keras.losses.CategoricalCrossentropy(),\n","      optimizer=tf.keras.optimizers.Adam(),\n","      metrics=[\"accuracy\"]\n","  )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:32.894850Z","iopub.status.busy":"2024-05-26T19:02:32.894263Z","iopub.status.idle":"2024-05-26T19:02:33.707488Z","shell.execute_reply":"2024-05-26T19:02:33.706584Z","shell.execute_reply.started":"2024-05-26T19:02:32.894816Z"},"trusted":true},"outputs":[],"source":["model.build(input_shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:33.708950Z","iopub.status.busy":"2024-05-26T19:02:33.708644Z","iopub.status.idle":"2024-05-26T19:02:33.740988Z","shell.execute_reply":"2024-05-26T19:02:33.740025Z","shell.execute_reply.started":"2024-05-26T19:02:33.708924Z"},"trusted":true},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:33.742994Z","iopub.status.busy":"2024-05-26T19:02:33.742322Z","iopub.status.idle":"2024-05-26T19:02:33.747815Z","shell.execute_reply":"2024-05-26T19:02:33.746912Z","shell.execute_reply.started":"2024-05-26T19:02:33.742956Z"},"trusted":true},"outputs":[],"source":["# Create early stopping callback\n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\",\n","                                                  patience=3)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:02:33.749402Z","iopub.status.busy":"2024-05-26T19:02:33.749060Z","iopub.status.idle":"2024-05-26T19:02:33.759608Z","shell.execute_reply":"2024-05-26T19:02:33.758680Z","shell.execute_reply.started":"2024-05-26T19:02:33.749376Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","print(\"Num GPUs Avail able: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:08:00.419999Z","iopub.status.busy":"2024-05-26T19:08:00.419601Z","iopub.status.idle":"2024-05-26T19:13:57.518048Z","shell.execute_reply":"2024-05-26T19:13:57.516896Z","shell.execute_reply.started":"2024-05-26T19:08:00.419968Z"},"trusted":true},"outputs":[],"source":["history = model.fit(x=train_data,\n","                    epochs=10,\n","                    callbacks=[early_stopping],\n","                    \n","                   validation_data=test_data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:15:31.825523Z","iopub.status.busy":"2024-05-26T19:15:31.824686Z","iopub.status.idle":"2024-05-26T19:15:32.084817Z","shell.execute_reply":"2024-05-26T19:15:32.083739Z","shell.execute_reply.started":"2024-05-26T19:15:31.825489Z"},"trusted":true},"outputs":[],"source":["final_model_path =\"C:/fruit_recognition/client/src/predict/model.h5\"\n","model.save(final_model_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:15:33.673604Z","iopub.status.busy":"2024-05-26T19:15:33.673216Z","iopub.status.idle":"2024-05-26T19:15:33.872512Z","shell.execute_reply":"2024-05-26T19:15:33.871439Z","shell.execute_reply.started":"2024-05-26T19:15:33.673576Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.utils import plot_model\n","plot_model(model, to_file='mobilenet.png', show_shapes=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:15:37.558012Z","iopub.status.busy":"2024-05-26T19:15:37.556935Z","iopub.status.idle":"2024-05-26T19:15:45.221675Z","shell.execute_reply":"2024-05-26T19:15:45.220700Z","shell.execute_reply.started":"2024-05-26T19:15:37.557973Z"},"trusted":true},"outputs":[],"source":["# 绘制训练集和验证集的损失曲线\n","plt.plot(history.history['loss'], label='Train Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n","\n","# 绘制训练集和验证集的准确率曲线\n","plt.plot(history.history['accuracy'], label='Train Accuracy')\n","plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","plt.title('Training and Validation Accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()\n","\n","# 计算验证集的损失和准确率\n","loss, accuracy = model.evaluate(test_data)\n","print(f'Validation Loss: {loss:.4f}')\n","print(f'Validation Accuracy: {accuracy:.4f}')"]},{"cell_type":"markdown","metadata":{},"source":["## Predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:15:58.995426Z","iopub.status.busy":"2024-05-26T19:15:58.994595Z","iopub.status.idle":"2024-05-26T19:15:59.002537Z","shell.execute_reply":"2024-05-26T19:15:59.001578Z","shell.execute_reply.started":"2024-05-26T19:15:58.995391Z"},"trusted":true},"outputs":[],"source":["def create_data_batches(X, y=None, batch_size=batch_size, test_data=False):\n","    if test_data:\n","        print(\"Creating test data batches...\")\n","        data = tf.data.Dataset.from_tensor_slices((tf.constant(X))) # only filepaths (no labels)\n","        data_batch = data.map(process_image).batch(batch_size)\n","        return data_batch\n","    else:\n","        print(\"Creating data batches...\")\n","        # Turn filepaths and labels into Tensors\n","        data = tf.data.Dataset.from_tensor_slices((tf.constant(X),\n","                                                   tf.constant(y)))\n","        # Shuffling pathnames and labels before mapping image processor function is faster than shuffling images\n","        data = data.shuffle(buffer_size=len(X))\n","\n","        # Create (image, label) tuples (this also turns the iamge path into a preprocessed image)\n","        data = data.map(get_image_label)\n","\n","        # Turn the training data into batches\n","        data_batch = data.batch(batch_size)\n","        return data_batch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:17:02.009498Z","iopub.status.busy":"2024-05-26T19:17:02.008647Z","iopub.status.idle":"2024-05-26T19:17:02.061148Z","shell.execute_reply":"2024-05-26T19:17:02.060146Z","shell.execute_reply.started":"2024-05-26T19:17:02.009463Z"},"trusted":true},"outputs":[],"source":["train_data = create_data_batches(X_train, y_train)\n","test_data = create_data_batches(X_test, test_data=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:17:03.599589Z","iopub.status.busy":"2024-05-26T19:17:03.599196Z","iopub.status.idle":"2024-05-26T19:17:12.213267Z","shell.execute_reply":"2024-05-26T19:17:12.212183Z","shell.execute_reply.started":"2024-05-26T19:17:03.599559Z"},"trusted":true},"outputs":[],"source":["predictions = model.predict(test_data)\n","predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:17:12.215307Z","iopub.status.busy":"2024-05-26T19:17:12.214976Z","iopub.status.idle":"2024-05-26T19:17:12.233935Z","shell.execute_reply":"2024-05-26T19:17:12.233018Z","shell.execute_reply.started":"2024-05-26T19:17:12.215280Z"},"trusted":true},"outputs":[],"source":["true_labels = [kinds[np.argmax(data)] for data in y_test]\n","pred_labels = [kinds[np.argmax(pred)] for pred in predictions]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:23:12.813669Z","iopub.status.busy":"2024-05-26T19:23:12.812607Z","iopub.status.idle":"2024-05-26T19:23:12.821327Z","shell.execute_reply":"2024-05-26T19:23:12.820304Z","shell.execute_reply.started":"2024-05-26T19:23:12.813622Z"},"trusted":true},"outputs":[],"source":["true_labels[:20]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:17:12.252377Z","iopub.status.busy":"2024-05-26T19:17:12.252026Z","iopub.status.idle":"2024-05-26T19:17:12.262963Z","shell.execute_reply":"2024-05-26T19:17:12.262073Z","shell.execute_reply.started":"2024-05-26T19:17:12.252350Z"},"trusted":true},"outputs":[],"source":["pred_labels[:20]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:17:12.264956Z","iopub.status.busy":"2024-05-26T19:17:12.264291Z","iopub.status.idle":"2024-05-26T19:17:12.276947Z","shell.execute_reply":"2024-05-26T19:17:12.275970Z","shell.execute_reply.started":"2024-05-26T19:17:12.264919Z"},"trusted":true},"outputs":[],"source":["print(accuracy_score(true_labels, pred_labels))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","print(\"TensorFlow version:\", tf.__version__)\n","print(\"tf.keras version:\", tf.keras.__version__)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:23:18.912898Z","iopub.status.busy":"2024-05-26T19:23:18.912484Z","iopub.status.idle":"2024-05-26T19:23:22.547140Z","shell.execute_reply":"2024-05-26T19:23:22.546181Z","shell.execute_reply.started":"2024-05-26T19:23:18.912863Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","# Function to preprocess the image\n","def preprocess_image(image_path):\n","    image = tf.io.read_file(image_path)\n","    image = tf.image.decode_jpeg(image, channels=3)\n","    image = tf.image.resize(image, [224, 224])  # Resize to match the model input shape\n","    image = tf.expand_dims(image, axis=0)  # Add batch dimension\n","    image /= 255.0  # Normalize to [0, 1] range\n","    return image\n","# Load the trained model\n","model_path = \"C:/fruit_recognition/client/src/predict/model.h5\"\n","model = tf.keras.models.load_model(model_path, custom_objects={'KerasLayer': hub.KerasLayer})\n","\n","# Path to the test image\n","test_image_path = 'C:/fruit_recognition/client/src/predict/Image/Image_1.jpg'\n","\n","# Preprocess the test image\n","test_image = preprocess_image(test_image_path)\n","\n","# Use the loaded model to predict the class of the test image\n","predictions = model.predict(test_image)\n","\n","# Get the top 5 class indices and corresponding probabilities\n","top5_indices = np.argsort(predictions[0])[-5:][::-1]\n","top5_probabilities = predictions[0][top5_indices]\n","\n","# Get the corresponding class labels\n","class_names = kinds  # Replace with the actual list of class names\n","top5_labels = [class_names[i] for i in top5_indices]\n","\n","# Display the top 5 predictions\n","print(\"Top 5 Predictions:\")\n","for label, probability in zip(top5_labels, top5_probabilities):\n","    print(f\"{label}: {probability:.4f}\")\n","\n","# Display the predicted class\n","class_index = np.argmax(predictions[0])\n","class_label = class_names[class_index]\n","print(f\"\\nThe predicted class of the test image is: {class_label}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-26T19:07:53.350718Z","iopub.status.idle":"2024-05-26T19:07:53.351076Z","shell.execute_reply":"2024-05-26T19:07:53.350915Z","shell.execute_reply.started":"2024-05-26T19:07:53.350900Z"},"trusted":true},"outputs":[],"source":["\n","print(tf.__version__)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-26T19:07:53.352832Z","iopub.status.idle":"2024-05-26T19:07:53.353175Z","shell.execute_reply":"2024-05-26T19:07:53.353004Z","shell.execute_reply.started":"2024-05-26T19:07:53.352991Z"},"trusted":true},"outputs":[],"source":["import pkg_resources\n","\n","package_name = 'tensorflow-metadata'\n","version = pkg_resources.get_distribution(package_name).version\n","print(f\"{package_name} version: {version}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-26T19:07:53.354475Z","iopub.status.idle":"2024-05-26T19:07:53.354973Z","shell.execute_reply":"2024-05-26T19:07:53.354749Z","shell.execute_reply.started":"2024-05-26T19:07:53.354723Z"},"trusted":true},"outputs":[],"source":["import json\n","from datetime import datetime\n","\n","\n","kinds_str_list = ', '.join(kinds.tolist())\n","\n","# Thông tin cần thiết để tạo metadata.json\n","metadata = {\n","    \"tfjsVersion\": \"2.15.0\",\n","    \"tmVersion\": \"0.14.0\",\n","    \"timeStamp\": datetime.utcnow().isoformat() + \"Z\",\n","    \"userMetadata\": {},\n","    \"modelName\": \"tm-my-image-model\",\n","    \"labels\": kinds_str_list,  # Thay thế bằng các nhãn thực tế của bạn\n","    \"imageSize\": 224\n","}\n","\n","# Đường dẫn lưu metadata.json\n","output_path = '/kaggle/working/metadata.json'\n","\n","# Tạo tệp metadata.json\n","with open(output_path, 'w') as f:\n","    json.dump(metadata, f, indent=2)\n","\n","print(f\"metadata.json file created successfully at {output_path}.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-26T19:07:53.356608Z","iopub.status.idle":"2024-05-26T19:07:53.357053Z","shell.execute_reply":"2024-05-26T19:07:53.356846Z","shell.execute_reply.started":"2024-05-26T19:07:53.356827Z"},"trusted":true},"outputs":[],"source":["import subprocess\n","\n","# Define the shell command to convert the TensorFlow.js model\n","command = \"tensorflowjs_converter --input_format=keras /kaggle/working/model.h5 /kaggle/working/\"\n","\n","# Execute the shell command\n","subprocess.run(command, shell=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T19:24:52.896739Z","iopub.status.busy":"2024-05-26T19:24:52.896323Z","iopub.status.idle":"2024-05-26T19:24:52.903391Z","shell.execute_reply":"2024-05-26T19:24:52.902413Z","shell.execute_reply.started":"2024-05-26T19:24:52.896707Z"},"trusted":true},"outputs":[],"source":["kinds"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":952827,"sourceId":3173719,"sourceType":"datasetVersion"},{"datasetId":4584822,"sourceId":7824494,"sourceType":"datasetVersion"},{"modelInstanceId":2610,"sourceId":3676,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.4"}},"nbformat":4,"nbformat_minor":4}
